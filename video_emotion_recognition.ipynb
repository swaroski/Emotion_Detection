{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "\n\nIMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE!\n\nImporting the numpy c-extensions failed.\n- Try uninstalling and reinstalling numpy.\n- If you have already done that, then:\n  1. Check that you expected to use Python3.7 from \"C:\\Users\\bhise\\Anaconda3\\envs\\tf_gpu\\python.exe\",\n     and that you have no directories in your PATH or PYTHONPATH that can\n     interfere with the Python and numpy version \"1.17.4\" you're trying to use.\n  2. If (1) looks fine, you can open a new issue at\n     https://github.com/numpy/numpy/issues.  Please include details on:\n     - how you installed Python\n     - how you installed numpy\n     - your operating system\n     - whether or not you have multiple versions of Python installed\n     - if you built from source, your compiler versions and ideally a build log\n\n- If you're working with a numpy git repository, try `git clean -xdf`\n  (removes all files not under version control) and rebuild numpy.\n\nNote: this error has many possible causes, so please don't comment on\nan existing issue about this - open a new one instead.\n\nOriginal error was: DLL load failed: The specified module could not be found.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\numpy\\core\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmultiarray\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\numpy\\core\\multiarray.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0moverrides\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_multiarray_umath\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\numpy\\core\\overrides.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m from numpy.core._multiarray_umath import (\n\u001b[0m\u001b[0;32m      8\u001b[0m     add_docstring, implement_array_function, _get_implementing_args)\n",
      "\u001b[1;31mImportError\u001b[0m: DLL load failed: The specified module could not be found.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-8cd9683e5b6e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m### General imports ###\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdivision\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\numpy\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    140\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_distributor_init\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 142\u001b[1;33m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    143\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\numpy\\core\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     45\u001b[0m \"\"\" % (sys.version_info[0], sys.version_info[1], sys.executable,\n\u001b[0;32m     46\u001b[0m         __version__, exc)\n\u001b[1;32m---> 47\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0menvkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menv_added\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: \n\nIMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE!\n\nImporting the numpy c-extensions failed.\n- Try uninstalling and reinstalling numpy.\n- If you have already done that, then:\n  1. Check that you expected to use Python3.7 from \"C:\\Users\\bhise\\Anaconda3\\envs\\tf_gpu\\python.exe\",\n     and that you have no directories in your PATH or PYTHONPATH that can\n     interfere with the Python and numpy version \"1.17.4\" you're trying to use.\n  2. If (1) looks fine, you can open a new issue at\n     https://github.com/numpy/numpy/issues.  Please include details on:\n     - how you installed Python\n     - how you installed numpy\n     - your operating system\n     - whether or not you have multiple versions of Python installed\n     - if you built from source, your compiler versions and ideally a build log\n\n- If you're working with a numpy git repository, try `git clean -xdf`\n  (removes all files not under version control) and rebuild numpy.\n\nNote: this error has many possible causes, so please don't comment on\nan existing issue about this - open a new one instead.\n\nOriginal error was: DLL load failed: The specified module could not be found.\n"
     ]
    }
   ],
   "source": [
    "### General imports ###\n",
    "from __future__ import division\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from time import sleep\n",
    "import re\n",
    "import os\n",
    "\n",
    "\n",
    "import requests\n",
    "import argparse\n",
    "from collections import OrderedDict\n",
    "\n",
    "### Image processing ###\n",
    "import cv2\n",
    "from scipy.ndimage import zoom\n",
    "from scipy.spatial import distance\n",
    "import imutils\n",
    "from scipy import ndimage\n",
    "import dlib\n",
    "from imutils import face_utils\n",
    "\n",
    "### Model ###\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "def gen():\n",
    "    \"\"\"\n",
    "    Video streaming generator function.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Start video capute. 0 = Webcam, 1 = Video file, -1 = Webcam for Web\n",
    "    video_capture = cv2.VideoCapture(0)\n",
    "    \n",
    "    # Image shape\n",
    "    shape_x = 48\n",
    "    shape_y = 48\n",
    "    input_shape = (shape_x, shape_y, 1)\n",
    "    \n",
    "    # We have 7 emotions\n",
    "    nClasses = 7\n",
    "    \n",
    "    # Timer until the end of the recording\n",
    "    end = 0\n",
    "    \n",
    "    # Count number of eye blinks (not used in model prediction)\n",
    "    def eye_aspect_ratio(eye):\n",
    "        \n",
    "        A = distance.euclidean(eye[1], eye[5])\n",
    "        B = distance.euclidean(eye[2], eye[4])\n",
    "        C = distance.euclidean(eye[0], eye[3])\n",
    "        ear = (A + B) / (2.0 * C)\n",
    "        \n",
    "        return ear\n",
    "    \n",
    "    # Detect facial landmarks and return coordinates (not used in model prediction but in visualization)\n",
    "    def detect_face(frame):\n",
    "        \n",
    "        #Cascade classifier pre-trained model\n",
    "        cascPath = (\"C:\\\\Users\\\\bhise\\\\new_project\\\\data\\\\face_landmarks.dat\")\n",
    "        faceCascade = cv2.CascadeClassifier(cascPath)\n",
    "        \n",
    "        #BGR -> Gray conversion\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        #Cascade MultiScale classifier\n",
    "        detected_faces = faceCascade.detectMultiScale(gray,scaleFactor=1.1,minNeighbors=6,\n",
    "                                                      minSize=(shape_x, shape_y),\n",
    "                                                      flags=cv2.CASCADE_SCALE_IMAGE)\n",
    "        coord = []\n",
    "                                                      \n",
    "        for x, y, w, h in detected_faces :\n",
    "            if w > 100 :\n",
    "                # Square around the landmarks\n",
    "                sub_img=frame[y:y+h,x:x+w]\n",
    "                # Put a rectangle around the face\n",
    "                cv2.rectangle(frame,(x,y),(x+w,y+h),(0, 255,255),1)\n",
    "                coord.append([x,y,w,h])\n",
    "                                                          \n",
    "        return gray, detected_faces, coord\n",
    "    \n",
    "    #  Zoom on the face of the person\n",
    "    def extract_face_features(faces, offset_coefficients=(0.075, 0.05)):\n",
    "        \n",
    "        # Each face identified\n",
    "        gray = faces[0]\n",
    "        \n",
    "        # ID of each face identifies\n",
    "        detected_face = faces[1]\n",
    "        \n",
    "        new_face = []\n",
    "        \n",
    "        for det in detected_face :\n",
    "            # Region in which the face is detected\n",
    "            # x, y represent the starting point, w the width (moving right) and h the height (moving up)\n",
    "            x, y, w, h = det\n",
    "            \n",
    "            #Offset coefficient (margins), np.floor takes the lowest integer (delete border of the image)\n",
    "            horizontal_offset = np.int(np.floor(offset_coefficients[0] * w))\n",
    "            vertical_offset = np.int(np.floor(offset_coefficients[1] * h))\n",
    "            \n",
    "            # Coordinates of the extracted face\n",
    "            extracted_face = gray[y+vertical_offset:y+h, x+horizontal_offset:x-horizontal_offset+w]\n",
    "            \n",
    "            #Zoom on the extracted face\n",
    "            new_extracted_face = zoom(extracted_face, (shape_x / extracted_face.shape[0],shape_y / extracted_face.shape[1]))\n",
    "            \n",
    "            # Cast type to float\n",
    "            new_extracted_face = new_extracted_face.astype(np.float32)\n",
    "            \n",
    "            # Scale the new image\n",
    "            new_extracted_face /= float(new_extracted_face.max())\n",
    "            \n",
    "            # Append the face to the list\n",
    "            new_face.append(new_extracted_face)\n",
    "        \n",
    "        return new_face\n",
    "    \n",
    "    # Initiate Landmarks\n",
    "    (lStart, lEnd) = face_utils.FACIAL_LANDMARKS_IDXS[\"left_eye\"]\n",
    "    (rStart, rEnd) = face_utils.FACIAL_LANDMARKS_IDXS[\"right_eye\"]\n",
    "    \n",
    "    (nStart, nEnd) = face_utils.FACIAL_LANDMARKS_IDXS[\"nose\"]\n",
    "    (mStart, mEnd) = face_utils.FACIAL_LANDMARKS_IDXS[\"mouth\"]\n",
    "    (jStart, jEnd) = face_utils.FACIAL_LANDMARKS_IDXS[\"jaw\"]\n",
    "    \n",
    "    (eblStart, eblEnd) = face_utils.FACIAL_LANDMARKS_IDXS[\"left_eyebrow\"]\n",
    "    (ebrStart, ebrEnd) = face_utils.FACIAL_LANDMARKS_IDXS[\"right_eyebrow\"]\n",
    "    \n",
    "    # Load the pre-trained X-Ception model\n",
    "    model = load_model(\"C:\\\\Users\\\\bhise\\\\new_project\\\\data\\\\video.h5\")\n",
    "    \n",
    "    # Load the face detector\n",
    "    face_detect = dlib.get_frontal_face_detector()\n",
    "    \n",
    "    # Load the facial landmarks predictor\n",
    "    predictor_landmarks  = dlib.shape_predictor(\"C:\\\\Users\\\\bhise\\\\new_project\\\\data\\\\face_landmarks.dat\")\n",
    "\n",
    "    # Prediction vector\n",
    "    predictions = []\n",
    "    \n",
    "    # Timer\n",
    "    global k\n",
    "    k = 0\n",
    "    max_time = 15\n",
    "    start = time.time()\n",
    "    \n",
    "    angry_0 = []\n",
    "    disgust_1 = []\n",
    "    fear_2 = []\n",
    "    happy_3 = []\n",
    "    sad_4 = []\n",
    "    surprise_5 = []\n",
    "    neutral_6 = []\n",
    "\n",
    "    # Record for 45 seconds\n",
    "    while end - start < max_time :\n",
    "        \n",
    "        k = k+1\n",
    "        end = time.time()\n",
    "        \n",
    "        # Capture frame-by-frame the video_capture initiated above\n",
    "        ret, frame = video_capture.read()\n",
    "        \n",
    "        # Face index, face by face\n",
    "        face_index = 0\n",
    "        \n",
    "        # Image to gray scale\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # All faces detected\n",
    "        rects = face_detect(gray, 1)\n",
    "        \n",
    "        #gray, detected_faces, coord = detect_face(frame)\n",
    "        \n",
    "        \n",
    "        # For each detected face\n",
    "        for (i, rect) in enumerate(rects):\n",
    "            \n",
    "            # Identify face coordinates\n",
    "            (x, y, w, h) = face_utils.rect_to_bb(rect)\n",
    "            face = gray[y:y+h,x:x+w]\n",
    "            \n",
    "            # Identify landmarks and cast to numpy\n",
    "            shape = predictor_landmarks(gray, rect)\n",
    "            shape = face_utils.shape_to_np(shape)\n",
    "            \n",
    "            # Zoom on extracted face\n",
    "            face = zoom(face, (shape_x / face.shape[0],shape_y / face.shape[1]))\n",
    "            \n",
    "            # Cast type float\n",
    "            face = face.astype(np.float32)\n",
    "            \n",
    "            # Scale the face\n",
    "            face /= float(face.max())\n",
    "            face = np.reshape(face.flatten(), (1, 48, 48, 1))\n",
    "            \n",
    "            # Make Emotion prediction on the face, outputs probabilities\n",
    "            prediction = model.predict(face)\n",
    "            \n",
    "            # For plotting purposes with Altair\n",
    "            angry_0.append(prediction[0][0].astype(float))\n",
    "            disgust_1.append(prediction[0][1].astype(float))\n",
    "            fear_2.append(prediction[0][2].astype(float))\n",
    "            happy_3.append(prediction[0][3].astype(float))\n",
    "            sad_4.append(prediction[0][4].astype(float))\n",
    "            surprise_5.append(prediction[0][5].astype(float))\n",
    "            neutral_6.append(prediction[0][6].astype(float))\n",
    "            \n",
    "            # Most likely emotion\n",
    "            prediction_result = np.argmax(prediction)\n",
    "            \n",
    "            # Append the emotion to the final list\n",
    "            predictions.append(str(prediction_result))\n",
    "            \n",
    "            # Draw rectangle around the face\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "            \n",
    "            # Top left : Put the ID of the face\n",
    "            cv2.putText(frame, \"Face #{}\".format(i + 1), (x - 10, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "            \n",
    "            # Draw all the landmarks dots\n",
    "            for (j, k) in shape:\n",
    "                cv2.circle(frame, (j, k), 1, (0, 0, 255), -1)\n",
    "        \n",
    "            # Add prediction probabilities on the top-left report\n",
    "            cv2.putText(frame, \"----------------\",(40,100 + 180*i), cv2.FONT_HERSHEY_SIMPLEX, 0.5, 155, 0)\n",
    "            cv2.putText(frame, \"Emotional report : Face #\" + str(i+1),(40,120 + 180*i), cv2.FONT_HERSHEY_SIMPLEX, 0.5, 155, 0)\n",
    "            cv2.putText(frame, \"Angry : \" + str(round(prediction[0][0],3)),(40,140 + 180*i), cv2.FONT_HERSHEY_SIMPLEX, 0.5, 155, 0)\n",
    "            cv2.putText(frame, \"Disgust : \" + str(round(prediction[0][1],3)),(40,160 + 180*i), cv2.FONT_HERSHEY_SIMPLEX, 0.5, 155, 0)\n",
    "            cv2.putText(frame, \"Fear : \" + str(round(prediction[0][2],3)),(40,180 + 180*i), cv2.FONT_HERSHEY_SIMPLEX, 0.5, 155, 1)\n",
    "            cv2.putText(frame, \"Happy : \" + str(round(prediction[0][3],3)),(40,200 + 180*i), cv2.FONT_HERSHEY_SIMPLEX, 0.5, 155, 1)\n",
    "            cv2.putText(frame, \"Sad : \" + str(round(prediction[0][4],3)),(40,220 + 180*i), cv2.FONT_HERSHEY_SIMPLEX, 0.5, 155, 1)\n",
    "            cv2.putText(frame, \"Surprise : \" + str(round(prediction[0][5],3)),(40,240 + 180*i), cv2.FONT_HERSHEY_SIMPLEX, 0.5, 155, 1)\n",
    "            cv2.putText(frame, \"Neutral : \" + str(round(prediction[0][6],3)),(40,260 + 180*i), cv2.FONT_HERSHEY_SIMPLEX, 0.5, 155, 1)\n",
    "            \n",
    "            # Annotate main image with the emotion label\n",
    "            if prediction_result == 0 :\n",
    "                cv2.putText(frame, \"Angry\",(x+w-10,y-10), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "            elif prediction_result == 1 :\n",
    "                cv2.putText(frame, \"Disgust\",(x+w-10,y-10), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "            elif prediction_result == 2 :\n",
    "                cv2.putText(frame, \"Fear\",(x+w-10,y-10), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "            elif prediction_result == 3 :\n",
    "                cv2.putText(frame, \"Happy\",(x+w-10,y-10), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "            elif prediction_result == 4 :\n",
    "                cv2.putText(frame, \"Sad\",(x+w-10,y-10), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "            elif prediction_result == 5 :\n",
    "                cv2.putText(frame, \"Surprise\",(x+w-10,y-10), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "            else :\n",
    "                cv2.putText(frame, \"Neutral\",(x+w-10,y-10), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "            \n",
    "            # Eye Detection and Blink Count\n",
    "            leftEye = shape[lStart:lEnd]\n",
    "            rightEye = shape[rStart:rEnd]\n",
    "            \n",
    "            # Compute Eye Aspect Ratio\n",
    "            leftEAR = eye_aspect_ratio(leftEye)\n",
    "            rightEAR = eye_aspect_ratio(rightEye)\n",
    "            ear = (leftEAR + rightEAR) / 2.0\n",
    "            \n",
    "            # And plot its contours\n",
    "            leftEyeHull = cv2.convexHull(leftEye)\n",
    "            rightEyeHull = cv2.convexHull(rightEye)\n",
    "            cv2.drawContours(frame, [leftEyeHull], -1, (0, 255, 0), 1)\n",
    "            cv2.drawContours(frame, [rightEyeHull], -1, (0, 255, 0), 1)\n",
    "            \n",
    "            # Detect Nose and draw its contours\n",
    "            nose = shape[nStart:nEnd]\n",
    "            noseHull = cv2.convexHull(nose)\n",
    "            cv2.drawContours(frame, [noseHull], -1, (0, 255, 0), 1)\n",
    "            \n",
    "            # Detect Mouth and draw its contours\n",
    "            mouth = shape[mStart:mEnd]\n",
    "            mouthHull = cv2.convexHull(mouth)\n",
    "            cv2.drawContours(frame, [mouthHull], -1, (0, 255, 0), 1)\n",
    "            \n",
    "            # Detect Jaw and draw its contours\n",
    "            jaw = shape[jStart:jEnd]\n",
    "            jawHull = cv2.convexHull(jaw)\n",
    "            cv2.drawContours(frame, [jawHull], -1, (0, 255, 0), 1)\n",
    "            \n",
    "            # Detect Eyebrows and draw its contours\n",
    "            ebr = shape[ebrStart:ebrEnd]\n",
    "            ebrHull = cv2.convexHull(ebr)\n",
    "            cv2.drawContours(frame, [ebrHull], -1, (0, 255, 0), 1)\n",
    "\n",
    "            ebl = shape[eblStart:eblEnd]\n",
    "            eblHull = cv2.convexHull(ebl)\n",
    "            cv2.drawContours(frame, [eblHull], -1, (0, 255, 0), 1)\n",
    "    \n",
    "        # Show number of faces captured\n",
    "        cv2.putText(frame,'Number of Faces : ' + str(len(rects)),(40, 40), cv2.FONT_HERSHEY_SIMPLEX, 1, 155, 1)\n",
    "        \n",
    "        # For flask, save image as t.jpg (rewritten at each step)\n",
    "        cv2.imwrite(\"C:\\\\Users\\\\bhise\\\\new_project\\\\tmp\\\\t.jpg\", frame)\n",
    "        \n",
    "        # Yield the image at each step\n",
    "        yield (b'--frame\\r\\n'\n",
    "               b'Content-Type: image/jpeg\\r\\n\\r\\n' + open(\"C:\\\\Users\\\\bhise\\\\new_project\\\\tmp\\\\t.jpg\", 'rb').read() + b'\\r\\n')\n",
    "        \n",
    "        # Emotion mapping\n",
    "        #emotion = {0:'Angry', 1:'Disgust', 2:'Fear', 3:'Happy', 4:'Neutral', 5:'Sad', 6:'Surprise'}\n",
    "        \n",
    "        # Once reaching the end, write the results to the personal file and to the overall file\n",
    "        if end-start > max_time - 1 :\n",
    "            with open(\"C:\\\\Users\\\\bhise\\\\new_project\\\\static\\\\db\\\\histo_perso.txt\", \"w\") as d:\n",
    "                d.write(\"density\"+'\\n')\n",
    "                for val in predictions :\n",
    "                    d.write(str(val)+'\\n')\n",
    "                d.close()\n",
    "            with open(\"C:\\\\Users\\\\bhise\\\\new_project\\\\static\\\\db\\\\histo.txt\", \"a\") as d:\n",
    "                for val in predictions :\n",
    "                    d.write(str(val)+'\\n')\n",
    "                d.close()\n",
    "    \n",
    "            rows = zip(angry_0,disgust_1,fear_2,happy_3,sad_4,surprise_5,neutral_6)\n",
    "\n",
    "            import csv\n",
    "            with open(\"C:\\\\Users\\\\bhise\\\\new_project\\\\static\\\\db\\\\prob.csv\", \"w\") as d:\n",
    "                writer = csv.writer(d)\n",
    "                for row in rows:\n",
    "                    writer.writerow(row)\n",
    "                d.close()\n",
    "\n",
    "            with open(\"C:\\\\Users\\\\bhise\\\\new_project\\\\static\\\\db\\\\prob_tot.csv\", \"a\") as d:\n",
    "                writer = csv.writer(d)\n",
    "                for row in rows:\n",
    "                    writer.writerow(row)\n",
    "                d.close()\n",
    "            K.clear_session()\n",
    "            break\n",
    "\n",
    "# Clear session to allow user to do another test afterwards\n",
    "#K.clear_session()\n",
    "\n",
    "\n",
    "    # d.write(','.join(str(i) for i in angry_0)+'\\n')\n",
    "    # d.write(','.join(str(i) for i in disgust_1)+'\\n')\n",
    "    #d.write(','.join(str(i) for i in fear_2)+'\\n')\n",
    "    # d.write(','.join(str(i) for i in happy_3)+'\\n')\n",
    "    #  d.write(','.join(str(i) for i in sad_4)+'\\n')\n",
    "    #  d.write(','.join(str(i) for i in surprise_5)+'\\n')\n",
    "#  d.write(','.join(str(i) for i in neutral_6)+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C:\\\\Users\\\\bhise\\\\new_project\\\\library', '']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "try:\n",
    "    user_paths = os.environ['PYTHONPATH'].split(os.pathsep)\n",
    "    print(user_paths)\n",
    "except KeyError:\n",
    "    user_paths = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow-GPU",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
